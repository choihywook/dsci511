{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Assignment Group 1\n", "\n", "## Module A _(25 points)_\n", "\n", "__A1.__ _(3 points)_ In this module, you will be working with the [Seinfeld Chronicles dataset](https://www.kaggle.com/thec03u5/seinfeld-chronicles). Create an account on [Kaggle](https://www.kaggle.com) and download the `scripts.csv` file from the dataset and move it into the `data` directory. Read the `data/scripts.csv` file as a text file line-by-line and examine the list you have loaded the data into. "]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["seinfeld = open(\"data/scripts.csv\", \"r\").readlines()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["__A2.__ _(2 points)_ Is it possible to work with this data, simply splitting by a delimiter? Explain any complexity in the data's structured format that necessitates an established format-specific file reader."]}, {"cell_type": "markdown", "metadata": {}, "source": ["_Response._ "]}, {"cell_type": "markdown", "metadata": {}, "source": ["__A3.__ _(5 points)_ Use the `csv` module to read the contents of the `data/scripts.csv` file into a list. Examine this list. How many unique speaking characters are present in the scripts in total?\n", "\n", "__Important__: please don't get stuck on cleaning text in this module! It's great to take note of issues in data and even address them, but the regular expressions (regex) required to get heavily into that work is ahead in __Chapter 4__ and so not required here. Please just count characters and words as best possible using the topics from Chapters 0&ndash;2 (na\u00efvely, even), and utilize the markdown response boxes to discuss what you see as being the challenges in working with these data and what solutions might be."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["import csv\n", "\n", "reader = csv.reader(open(\"data/scripts.csv\", \"r\"))\n", "seinfeld = list(reader)"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["for i in range(50):\n", "    print(seinfeld)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["__A4.__ _(2 points)_ Count the dialogue entries for the four major characters, \"JERRY\", \"GEORGE\", \"ELAINE\", and \"KRAMER\", using a dictionary (you are not allowed to use the Counter data structure for any component of this module). "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["__A5.__ _(3 points)_ Count the number of words spoken by each of the main characters using a dictionary."]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["__A6.__ _(5 points)_ Count how many times each word is spoken by the main characters using a dictionary, then sort these word counts in descending order, i.e. from the most commonly spoken words to least. [__Hint__: You can use either a lambda function or a list comprehension to do this.]"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["__A7.__ _(5 points)_ Load the `data/stop-words.txt` file into a list. Find the 10 most common words for each of the main characters that are not in this list of stop words. Put these most common words in a dictionary data strucutre."]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.5"}}, "nbformat": 4, "nbformat_minor": 2}